{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from skimage.measure import marching_cubes_lewiner, marching_cubes\n",
    "import nibabel\n",
    "import os\n",
    "import trimesh\n",
    "import numpy as np\n",
    "from natsort import natsorted\n",
    "import pymeshlab\n",
    "sorted = natsorted\n",
    "from numba import njit\n",
    "import cc3d\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "\n",
    "BRAIN_FOLDER = '/home/ruslan/mri/server_brains/'\n",
    "MASK_FOLDER = '/home/ruslan/mri/server_masks/'\n",
    "\n",
    "SAVE_FOLDER_INNER = 'new_mesh_objects_inner/'\n",
    "SAVE_FOLDER_OUTTER = 'new_mesh_objects_outter/'\n",
    "SAVE_FOLDER_FINAL = 'new_mesh_objects/'\n",
    "\n",
    "\n",
    "for f in [SAVE_FOLDER_INNER, SAVE_FOLDER_OUTTER, SAVE_FOLDER_FINAL]:\n",
    "    os.makedirs(f, exist_ok=True)\n",
    "    os.makedirs(f + 'seg', exist_ok=True)\n",
    "    os.makedirs(f + 'sseg', exist_ok=True)\n",
    "\n",
    "brain_img_names = sorted(glob.glob(BRAIN_FOLDER + '*_fcd.nii.gz'))\n",
    "brain_mask_names = sorted(glob.glob(MASK_FOLDER + '*.nii.gz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_edges(faces):\n",
    "    \"\"\"\n",
    "        input: array of faces\n",
    "        output: dict, keys = id of edge, value = faces that contains this edge\n",
    "    \"\"\"\n",
    "    edge_dict = {}\n",
    "    for face in faces:\n",
    "        keys = [\n",
    "            tuple(sorted((face[0], face[1]))), tuple(sorted((face[1], face[2]))), tuple(sorted((face[0], face[2])))\n",
    "        ]\n",
    "        for key in keys:\n",
    "            edge_dict[key] = edge_dict.get(key, 0) + 1\n",
    "    return edge_dict\n",
    "\n",
    "def get_vertex_labels(verts, mask):\n",
    "    \"\"\"\n",
    "        verts: list of 3d coordinates of vertices\n",
    "        mask: 3d binary array of mask\n",
    "        \n",
    "        labels: binary labels for each vertice\n",
    "    \"\"\"\n",
    "    vs = verts.astype('int32')\n",
    "    labels = []\n",
    "    for v_ in vs:\n",
    "        a, b, c = v_\n",
    "        labels += [mask[a, b, c]]\n",
    "    labels = np.array(labels)\n",
    "    return labels\n",
    "\n",
    "def get_edge_labels(v_labels, e_dict):\n",
    "    \"\"\"\n",
    "        v_labels: vertex_labels\n",
    "        e_dict: edge_dict\n",
    "        \n",
    "        e_labels: binary labels for each edge\n",
    "    \"\"\"\n",
    "    es = list(e_dict.keys())\n",
    "    e_labels = []\n",
    "    for i, (v1, v2) in enumerate(es):\n",
    "        e_labels += [v_labels[v1] or v_labels[v2]]\n",
    "    e_labels = np.array(e_labels)\n",
    "    return e_labels\n",
    "\n",
    "@njit\n",
    "def morph_3d(mask, l=5):\n",
    "    \"\"\"\n",
    "        3d dilation for masks\n",
    "    \"\"\"\n",
    "    d, h, w = mask.shape\n",
    "    mask_padded = np.zeros((d+2*l//2, h+2*l//2, w+2*l//2))\n",
    "    mask_padded[l//2: -l//2, l//2: -l//2, l//2: -l//2] = mask.copy()\n",
    "    for i in range(d):\n",
    "        for j in range(h):\n",
    "            for k in range(w):\n",
    "                mask[i, j, k] = np.all(mask_padded[i: i + l, j: j + l, k: k + l]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Extracting inner and outter meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for SAVE_FOLDER in [SAVE_FOLDER_INNER, SAVE_FOLDER_OUTTER]:\n",
    "    for i, br_name in enumerate(brain_img_names):\n",
    "        print(i)\n",
    "        brain = nibabel.load(br_name)\n",
    "        mask = nibabel.load(brain_mask_names[i]).get_fdata() > 0\n",
    "        brain_tensor = brain.get_fdata()\n",
    "        brain_tensor = brain_tensor > 0\n",
    "        if 'inner' in SAVE_FOLDER:\n",
    "            brain_tensor = brain.get_fdata() > 95\n",
    "            l = 7\n",
    "            t = 0.4\n",
    "            brain_tensor = gaussian_filter(brain_tensor.astype('float'), sigma=l)\n",
    "            brain_tensor = brain_tensor > 0.4\n",
    "            labels_in = brain_tensor\n",
    "            labels_out = cc3d.connected_components(labels_in, connectivity=6)\n",
    "            u, c = np.unique(labels_out, return_counts=True)\n",
    "            max_connected_label = np.argmax(c[1:]) + 1\n",
    "            brain_tensor = labels_out == max_connected_label\n",
    "        else:\n",
    "            brain_tensor = brain.get_fdata() > 0\n",
    "\n",
    "\n",
    "        verts, faces, normals, values = marching_cubes(brain_tensor, step_size=6, allow_degenerate=False, gradient_direction = 'ascent')\n",
    "        v_labels = get_vertex_labels(verts, mask)\n",
    "        print('vertex labels mean', v_labels.mean())\n",
    "\n",
    "\n",
    "        e_dict = count_edges(faces)\n",
    "        np_e_dict = np.array(list(e_dict.values()))\n",
    "        e_labels = get_edge_labels(v_labels, e_dict)\n",
    "        print('edge labels mean', v_labels.mean())\n",
    "\n",
    "\n",
    "        print('number of manifold edges', (np_e_dict == 2).sum())\n",
    "        print('number of non-manifold edges', (np_e_dict != 2).sum())\n",
    "\n",
    "\n",
    "        mesh_n = trimesh.base.Trimesh(vertices = verts, faces = faces, process = False)\n",
    "        mesh_n.export(SAVE_FOLDER + f\"{i}.obj\")\n",
    "\n",
    "        seg = e_labels + 1\n",
    "        sseg = np.zeros((len(e_dict), 2), dtype=np.int32)\n",
    "        sseg[np.arange(seg.size), seg-1] = 1\n",
    "\n",
    "        with open(SAVE_FOLDER + f\"{i}.obj\", 'a') as f:\n",
    "            for j, e in enumerate(e_dict):\n",
    "                f.write(f'\\ne {e[0]} {e[1]} {seg[j]}')\n",
    "        with open(SAVE_FOLDER + f\"{i}.obj\", 'r') as fin:\n",
    "            data = fin.read().splitlines(True)\n",
    "        with open(SAVE_FOLDER + f\"{i}.obj\", 'w') as fout:\n",
    "            fout.writelines(data[1:])\n",
    "\n",
    "        np.savetxt(SAVE_FOLDER + f'seg/{i}.eseg', seg)\n",
    "        np.savetxt(SAVE_FOLDER + f'sseg/{i}.seseg', sseg)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Combining inner and outter meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "                \n",
    "def count_vertices(data):\n",
    "    \"\"\"\n",
    "        return count of vertices, faces and edges\n",
    "    \"\"\"\n",
    "    for j in range(len(data)):\n",
    "        if data[j][0] != 'v':\n",
    "            a = j\n",
    "            break\n",
    "    for j in range(a, len(data)):\n",
    "        if data[j][0] != 'f':\n",
    "            b = j\n",
    "            break\n",
    "    return a, b - a , len(data) - b\n",
    "\n",
    "def shift_line(line, n):\n",
    "    \"\"\"\n",
    "        line: line from text description of .obj file. it starts with 'v', 'e' or 'f'\n",
    "        n: shift indexing by this number\n",
    "        \n",
    "        return: shifted line\n",
    "    \"\"\"\n",
    "    ls = line.split(' ')\n",
    "    joins = [ls[0], str(int(ls[1]) + n), str(int(ls[2]) + n)]\n",
    "    try:\n",
    "        if ls[0] == 'e':\n",
    "            joins.append(str(int(ls[3])))\n",
    "        else:\n",
    "            joins.append(str(int(ls[3]) + n))\n",
    "    except:\n",
    "        print(line)\n",
    "        print(ls)\n",
    "        raise ValueError\n",
    "    return \" \".join(joins) + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 16200 0.0011111111111110628\n",
      "1 15465 0.00032331070158431174\n",
      "2 14301 0.003985735263268397\n",
      "3 13530 0.00539541759053952\n",
      "4 17787 0.0026986001011974903\n",
      "5 16596 0.004760183176669042\n",
      "6 15633 0.0019829847118275623\n",
      "7 13767 0.0010895619960775704\n",
      "8 15414 0.0004541326067211138\n",
      "9 16653 0.0010208370864108751\n",
      "10 15084 0.0012596128347919233\n",
      "11 15624 0.0017921146953405742\n",
      "12 13365 0.0011971567527122584\n",
      "13 15192 0.0\n",
      "14 15387 0.0\n",
      "15 14871 0.0038329634859795014\n",
      "16 14904 0.0019457863660761188\n",
      "17 13914 0.0034497628288054916\n",
      "18 15330 0.004566210045662045\n",
      "19 16110 0.003910614525139744\n",
      "20 15690 0.001274697259400881\n",
      "21 14562 0.004188985029528913\n",
      "22 12708 0.0010229776518728695\n",
      "23 14070 0.0010660980810235365\n",
      "24 15315 0.0024159320927195083\n",
      "25 13209 0.0007570595805890257\n",
      "26 16401 0.0037192854094263428\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(len(brain_img_names)):\n",
    "    with open(SAVE_FOLDER_INNER + f\"{i}.obj\", 'r') as fin:\n",
    "        data_inner = fin.read().splitlines(True)\n",
    "    with open(SAVE_FOLDER_OUTTER + f\"{i}.obj\", 'r') as fin:\n",
    "        data_outter = fin.read().splitlines(True)\n",
    "    a1, b1, c1 = count_vertices(data_inner)\n",
    "    a2, b2, c2 = count_vertices(data_outter)\n",
    "\n",
    "    data = []\n",
    "    data += data_inner[:a1]\n",
    "    data += data_outter[:a2]\n",
    "    data += data_inner[a1: a1 + b1]\n",
    "    data += list(map(lambda x: shift_line(x, a1), data_outter[a2: a2 + b2]))\n",
    "#     data += data_inner[a1 + b1:]\n",
    "#     data += list(map(lambda x: shift_line(x, a1), data_outter[a2 + b2:]))\n",
    "\n",
    "    \n",
    "    with open(SAVE_FOLDER_FINAL + f\"{i}.obj\", 'w') as fout:\n",
    "        fout.writelines(data)\n",
    "    \n",
    "    seg_inner = np.loadtxt(SAVE_FOLDER_INNER + 'seg/' + f\"{i}.eseg\")\n",
    "    sseg_inner = np.loadtxt(SAVE_FOLDER_INNER + 'sseg/' + f\"{i}.seseg\")    \n",
    "    \n",
    "    seg_outter = np.loadtxt(SAVE_FOLDER_OUTTER + 'seg/' + f\"{i}.eseg\")\n",
    "    sseg_outter = np.loadtxt(SAVE_FOLDER_OUTTER + 'sseg/' + f\"{i}.seseg\")\n",
    "        \n",
    "    seg = np.concatenate([seg_inner, seg_outter])\n",
    "    sseg = np.concatenate([sseg_inner, sseg_outter])\n",
    "    print(i, c1 + c2, seg.mean() - 1)\n",
    "\n",
    "    np.savetxt(SAVE_FOLDER_FINAL + f'seg/{i}.eseg', seg)\n",
    "    np.savetxt(SAVE_FOLDER_FINAL + f'sseg/{i}.seseg', sseg)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for training MeshCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "FCD_FOLDER = '/home/ruslan/MeshCNN/datasets/fcd_seg/'\n",
    "\n",
    "if os.path.exists(FCD_FOLDER + 'test/cache'):\n",
    "    shutil.rmtree(FCD_FOLDER + 'test/cache')\n",
    "if os.path.exists(FCD_FOLDER + 'train/cache'):\n",
    "    shutil.rmtree(FCD_FOLDER + 'train/cache')\n",
    "    \n",
    "files = glob.glob(FCD_FOLDER + 'test/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "files = glob.glob(FCD_FOLDER + 'train/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "test_idxs = [1, 14]\n",
    "train_idxs = [i for i in range(len(brain_img_names)) if i not in test_idxs]\n",
    "\n",
    "for i in train_idxs:\n",
    "    shutil.copyfile(SAVE_FOLDER + f\"{i}.obj\", FCD_FOLDER + 'train/' + f\"{i}.obj\")\n",
    "    shutil.copyfile(SAVE_FOLDER + 'seg/'+ f\"{i}.eseg\", FCD_FOLDER + 'seg/' + f\"{i}.eseg\")\n",
    "    shutil.copyfile(SAVE_FOLDER + 'sseg/'+ f\"{i}.seseg\", FCD_FOLDER + 'sseg/' + f\"{i}.seseg\")\n",
    "\n",
    "for i in test_idxs:\n",
    "    shutil.copyfile(SAVE_FOLDER + f\"{i}.obj\", FCD_FOLDER + 'test/' + f\"{i}.obj\")\n",
    "    shutil.copyfile(SAVE_FOLDER + 'seg/'+ f\"{i}.eseg\", FCD_FOLDER + 'seg/' + f\"{i}.eseg\")\n",
    "    shutil.copyfile(SAVE_FOLDER + 'sseg/'+ f\"{i}.seseg\", FCD_FOLDER + 'sseg/' + f\"{i}.seseg\")   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shifting meshes from FreeSurfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 15\n",
    "base_names = ['lh.pial', 'lh.orig', 'rh.pial', 'rh.orig']\n",
    "def shift_mesh(i, base_name):\n",
    "    coords, faces, meta = nibabel.freesurfer.io.read_geometry(f'{i}_1_surf/{base_name}', read_metadata=True)\n",
    "    coords += meta['cras']\n",
    "    m = pymeshlab.Mesh(coords, faces)\n",
    "    ms = pymeshlab.MeshSet()\n",
    "    ms.add_mesh(m, base_name)\n",
    "    ms.save_current_mesh(f\"meshlab_objects/{i}_{base_name}.obj\")\n",
    "\n",
    "for i in range(N):\n",
    "    for base_name in base_names:\n",
    "        shift_mesh(i, base_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking good value for gauss sigma and threshold value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-61e6ff865aef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbase_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbase_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mshift_mesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-61e6ff865aef>\u001b[0m in \u001b[0;36mshift_mesh\u001b[0;34m(i, base_name)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbase_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'lh.pial'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lh.orig'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rh.pial'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rh.orig'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshift_mesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnibabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreesurfer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_geometry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{i}_1_surf/{base_name}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcoords\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cras'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpymeshlab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/meshcnn/lib/python3.6/site-packages/nibabel/freesurfer/io.py\u001b[0m in \u001b[0;36mread_geometry\u001b[0;34m(filepath, read_metadata, read_stamp)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mNEW_QUAD_MAGIC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16777213\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mmagic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fread3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmagic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mQUAD_MAGIC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNEW_QUAD_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Quad file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mnvert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fread3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/meshcnn/lib/python3.6/site-packages/nibabel/freesurfer/io.py\u001b[0m in \u001b[0;36m_fread3\u001b[0;34m(fobj)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mA\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0mbyte\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \"\"\"\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\">u1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb1\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb2\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for i, br_name in enumerate(brain_img_names):\n",
    "    print(i)\n",
    "    brain = nibabel.load(br_name)\n",
    "    mask = nibabel.load(brain_mask_names[i]).get_fdata() > 0\n",
    "    brain_tensor = brain.get_fdata() > 95\n",
    "    l = 7\n",
    "    brain_tensor = gaussian_filter(brain_tensor.astype('float'), sigma=l)\n",
    "    nifti = nibabel.Nifti1Image(brain_tensor.astype('float'), brain.affine)\n",
    "    nibabel.save(nifti, f\"{i}_gauss_g_{l}.nii.gz\")\n",
    "    t = 0.4\n",
    "    nifti_t = nibabel.Nifti1Image((brain_tensor > t).astype('float'), brain.affine)\n",
    "    nibabel.save(nifti_t, f\"{i}_gauss_g_{l}_t_{t}.nii.gz\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meshcnn",
   "language": "python",
   "name": "meshcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
